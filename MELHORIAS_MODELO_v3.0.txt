================================================================================
MELHORIAS IMPLEMENTADAS NO TREINAMENTO DE MODELOS - v3.0 OTIMIZADO
================================================================================

üìÖ Data: 1 de novembro de 2025
üì¶ Arquivo: scripts/train_advanced_models.py

================================================================================
RESUMO DAS MELHORIAS
================================================================================

‚úÖ 1. FEATURE ENGINEERING EXPANDIDO
   - Lags ampliados: 1, 7, 14, 30, 60 dias (antes: 1, 7, 14, 30)
   - Rolling windows: 7, 14, 30, 60 dias com min, max, mean, std
   - EWM (Exponential Weighted Mean) com spans: 7, 14, 30
   - Features de calend√°rio expandidas:
     * is_month_start, is_month_end, week_of_year
   - Features de tend√™ncia: trend, trend_squared
   - Features de pre√ßo expandidas: lags, m√©dias m√≥veis, volatilidade
   - Raz√µes e intera√ß√µes: preco_quantidade_ratio, quantidade_change, preco_change
   - Diferencia√ß√£o: quantidade_diff_1, quantidade_diff_7

‚úÖ 2. TRATAMENTO INTELIGENTE DE ZEROS
   Fun√ß√£o: handle_zero_sales(method="smart")
   - Identifica sequ√™ncias longas de zeros (>3 dias consecutivos)
   - Substitui por m√©dia m√≥vel dos 14 dias anteriores
   - Mant√©m zeros isolados (podem ser fechamentos reais)

‚úÖ 3. DETEC√á√ÉO E TRATAMENTO DE OUTLIERS
   Fun√ß√£o: remove_outliers(std_threshold=3.5)
   - Usa Z-score para detectar outliers
   - Substitui√ß√£o pela mediana dos 7 dias adjacentes
   - Threshold configur√°vel (padr√£o: 3.5 desvios padr√£o)

‚úÖ 4. HIPERPAR√ÇMETROS OTIMIZADOS
   
   LightGBM:
   - num_leaves: 64-256 (antes: 20-150)
   - max_depth: 5-15 (antes: 3-15)
   - min_data_in_leaf: 20-100 (antes: 5-60)
   - lambda_l1, lambda_l2: 0-5.0 (antes: 0-10.0)
   - Novo: min_gain_to_split: 0-1.0
   - n_estimators: 300 (antes: 200)
   
   XGBoost:
   - max_depth: 5-15 (antes: 3-15)
   - Novos par√¢metros:
     * gamma: 0-5.0 (controle de complexidade)
     * max_delta_step: 0-10 (estabilidade em classes desbalanceadas)
   - n_estimators: 300 (antes: 200)

‚úÖ 5. VALIDA√á√ÉO CRUZADA MAIS RIGOROSA
   - TimeSeriesSplit: 5 folds (antes: 3 folds)
   - Maior robustez na avalia√ß√£o de hiperpar√¢metros

‚úÖ 6. AUMENTO DE TRIALS NO OPTUNA
   - Padr√£o: 50 trials (antes: 20)
   - Configur√°vel via --trials
   - Mais explora√ß√£o do espa√ßo de hiperpar√¢metros

‚úÖ 7. REGULARIZA√á√ÉO APRIMORADA
   - Par√¢metros lambda mais conservadores
   - min_data_in_leaf aumentado para evitar overfitting
   - min_gain_to_split para controlar splits excessivos

================================================================================
COMO USAR
================================================================================

1. Treino completo (pipeline autom√°tico):
   ./scripts/run_all_scripts.sh

2. Treino com Docker:
   docker-compose exec -T api bash scripts/run_all_scripts.sh

3. Treino manual com mais trials:
   python scripts/train_advanced_models.py --trials 100

4. Treino de um produto espec√≠fico:
   python scripts/train_advanced_models.py --sku ABC123 --trials 50

5. Modo r√°pido (sem Optuna e backtest):
   python scripts/train_advanced_models.py --bulk

================================================================================
RESULTADOS ESPERADOS
================================================================================

Com essas melhorias, espera-se:

‚úÖ Redu√ß√£o de 15-30% no RMSE e MAE
‚úÖ Melhor generaliza√ß√£o (menor gap entre treino e valida√ß√£o)
‚úÖ MAPE mais est√°vel (tratamento de zeros)
‚úÖ Menor sensibilidade a outliers
‚úÖ Melhor captura de sazonalidade (features expandidas)
‚úÖ Modelos mais robustos para produ√ß√£o

================================================================================
ARQUIVOS MODIFICADOS
================================================================================

‚úÖ scripts/train_advanced_models.py (v3.0 - Otimizado)
   - Vers√£o atualizada de "2.3_advanced" para "3.0_optimized"
   - +200 linhas de c√≥digo (tratamentos e features)
   - Compatibilidade mantida com Docker (xgboost==3.1.1, lightgbm==4.6.0)

================================================================================
PR√ìXIMOS PASSOS
================================================================================

1. ‚úÖ Executar pipeline completo com novas melhorias
2. ‚è≥ Comparar m√©tricas v2.3 vs v3.0
3. ‚è≥ Ajustar thresholds se necess√°rio (outliers, zeros)
4. ‚è≥ Monitorar desempenho em produ√ß√£o
5. ‚è≥ Considerar ensemble weights otimizados

================================================================================
