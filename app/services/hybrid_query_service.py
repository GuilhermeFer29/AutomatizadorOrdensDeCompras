"""
Servi√ßo H√≠brido: RAG + SQL para responder QUALQUER pergunta sobre produtos.

ESTRAT√âGIA:
1. LLM analisa a pergunta e decide qual ferramenta usar
2. Perguntas estruturadas (filtros, agrega√ß√µes) ‚Üí SQL Tool
3. Perguntas sem√¢nticas (descri√ß√µes, compara√ß√µes) ‚Üí RAG
4. Perguntas complexas ‚Üí Combina ambos
"""

from typing import Dict, Any
from sqlmodel import Session
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
import json


def analyze_query_intent(user_question: str) -> Dict[str, Any]:
    """
    Usa LLM para analisar a inten√ß√£o da pergunta e decidir qual ferramenta usar.
    
    Returns:
        {
            "query_type": "sql" | "rag" | "hybrid",
            "needs_filter": bool,
            "filters": {...},
            "semantic_query": str
        }
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.1
    )
    
    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um analisador de consultas de banco de dados.

Analise a pergunta do usu√°rio e determine:
1. Se precisa de consulta SQL estruturada (filtros, agrega√ß√µes, compara√ß√µes num√©ricas)
2. Se precisa de busca sem√¢ntica RAG (descri√ß√µes, caracter√≠sticas, informa√ß√µes textuais)
3. Ou se precisa de ambos (h√≠brido)

PERGUNTA: {question}

Retorne um JSON com:
{{
    "query_type": "sql" | "rag" | "hybrid",
    "needs_stock_filter": true/false,
    "stock_filter_type": "low" | "high" | "all" | null,
    "needs_category_filter": true/false,
    "category": "categoria" | null,
    "needs_sorting": true/false,
    "sort_by": "stock_asc" | "stock_desc" | null,
    "semantic_aspect": "descri√ß√£o do que buscar semanticamente" | null,
    "reasoning": "breve explica√ß√£o da decis√£o"
}}

Responda APENAS com o JSON, sem texto adicional.""")
    
    try:
        response = llm.invoke(prompt.format(question=user_question))
        # Remove markdown code blocks se existirem
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        
        return json.loads(content.strip())
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao analisar intent: {e}")
        # Fallback: usa RAG por padr√£o
        return {
            "query_type": "rag",
            "needs_stock_filter": False,
            "reasoning": "Fallback para RAG devido a erro na an√°lise"
        }


def execute_hybrid_query(user_question: str, db_session: Session) -> str:
    """
    Executa consulta h√≠brida combinando SQL e RAG conforme necess√°rio.
    
    Args:
        user_question: Pergunta do usu√°rio
        db_session: Sess√£o do banco de dados
        
    Returns:
        Resposta formatada em linguagem natural
    """
    # 1. Analisa a inten√ß√£o da pergunta
    intent = analyze_query_intent(user_question)
    print(f"üß† Intent detectado: {intent.get('query_type')} - {intent.get('reasoning')}")
    
    query_type = intent.get("query_type", "rag")
    
    # 2. Executa consulta SQL se necess√°rio
    sql_results = None
    if query_type in ["sql", "hybrid"]:
        sql_results = execute_sql_query(intent, db_session)
        print(f"üìä SQL retornou {len(sql_results) if isinstance(sql_results, list) else 'dados'}")
    
    # 3. Executa RAG se necess√°rio
    rag_response = None
    if query_type in ["rag", "hybrid"]:
        from app.services.rag_service import query_product_catalog_with_google_rag
        
        # Se tem resultados SQL, enriquece a pergunta com contexto
        if sql_results:
            enhanced_query = f"{user_question}\n\nDados estruturados dispon√≠veis: {json.dumps(sql_results, ensure_ascii=False)}"
            rag_response = query_product_catalog_with_google_rag(enhanced_query)
        else:
            rag_response = query_product_catalog_with_google_rag(user_question)
        
        print(f"ü§ñ RAG respondeu: {rag_response[:100]}...")
    
    # 4. Combina resultados e gera resposta final
    return format_final_response(user_question, sql_results, rag_response, intent)


def execute_sql_query(intent: Dict[str, Any], db_session: Session) -> Any:
    """
    Executa consulta SQL baseada no intent analisado.
    """
    from app.services.sql_query_tool import (
        query_products_with_filters,
        get_stock_statistics,
        get_products_sorted_by_stock
    )
    
    # Consulta produtos com estoque baixo
    if intent.get("needs_stock_filter") and intent.get("stock_filter_type") == "low":
        return query_products_with_filters(
            db_session,
            estoque_baixo=True,
            categoria=intent.get("category"),
            limit=50
        )
    
    # Consulta produtos ordenados por estoque
    if intent.get("needs_sorting"):
        order = "asc" if intent.get("sort_by") == "stock_asc" else "desc"
        return get_products_sorted_by_stock(db_session, order=order, limit=20)
    
    # Estat√≠sticas gerais
    if "estat√≠stica" in intent.get("reasoning", "").lower() or "quantos" in intent.get("reasoning", "").lower():
        return get_stock_statistics(db_session)
    
    # Fallback: retorna produtos com filtros gerais
    return query_products_with_filters(
        db_session,
        estoque_baixo=intent.get("stock_filter_type") == "low",
        categoria=intent.get("category"),
        limit=50
    )


def format_final_response(
    question: str,
    sql_results: Any,
    rag_response: str,
    intent: Dict[str, Any]
) -> str:
    """
    Formata resposta final combinando SQL e RAG.
    """
    # Se s√≥ tem RAG, retorna direto
    if sql_results is None and rag_response:
        return rag_response
    
    # Se s√≥ tem SQL, formata os dados
    if sql_results and not rag_response:
        return format_sql_results(sql_results, question)
    
    # Se tem ambos, usa LLM para combinar
    if sql_results and rag_response:
        return combine_with_llm(question, sql_results, rag_response)
    
    return "Desculpe, n√£o consegui encontrar informa√ß√µes relevantes para sua pergunta."


def format_sql_results(results: Any, question: str) -> str:
    """
    Formata resultados SQL em linguagem natural.
    Limita a 10 produtos para evitar respostas muito longas.
    """
    # Se √© estat√≠stica
    if isinstance(results, dict) and "total_produtos" in results:
        return (
            f"üìä **Estat√≠sticas do Estoque:**\n\n"
            f"‚Ä¢ Total de produtos: {results['total_produtos']}\n"
            f"‚Ä¢ Produtos com estoque baixo: {results['produtos_estoque_baixo']}\n"
            f"‚Ä¢ Estoque total: {results['estoque_total_unidades']} unidades\n"
        )
    
    # Se √© lista de produtos
    if isinstance(results, list):
        if not results:
            return "N√£o encontrei produtos que atendam aos crit√©rios da sua busca."
        
        # Produtos com estoque baixo
        estoque_baixo = [p for p in results if p.get("estoque_baixo")]
        if estoque_baixo:
            total = len(estoque_baixo)
            limite = 10  # Limita a 10 produtos para n√£o exceder tamanho da coluna
            
            response = f"‚ö†Ô∏è **Encontrei {total} produto(s) com estoque baixo:**\n\n"
            
            for p in estoque_baixo[:limite]:
                diferenca = p.get("diferenca", 0)
                response += (
                    f"‚Ä¢ **{p['nome']}** (SKU: {p['sku']})\n"
                    f"  - Estoque: {p['estoque_atual']}/{p['estoque_minimo']} unidades\n"
                    f"  - Faltam: {abs(diferenca)} unidades\n\n"
                )
            
            if total > limite:
                response += f"\n_...e mais {total - limite} produto(s). Use filtros para refinar a busca._"
            
            return response
        
        # Produtos gerais
        total = len(results)
        limite = 10
        
        response = f"üì¶ **Encontrei {total} produto(s):**\n\n"
        for p in results[:limite]:
            response += (
                f"‚Ä¢ **{p['nome']}** (SKU: {p['sku']})\n"
                f"  - Estoque: {p['estoque_atual']} unidades\n\n"
            )
        
        if total > limite:
            response += f"\n_...e mais {total - limite} produto(s)._"
        
        return response
    
    return str(results)


def combine_with_llm(question: str, sql_data: Any, rag_response: str) -> str:
    """
    Usa LLM para combinar dados SQL e resposta RAG em uma resposta coerente.
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.3
    )
    
    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um assistente especializado em produtos industriais.

Combine as informa√ß√µes estruturadas do banco de dados com o contexto sem√¢ntico para responder a pergunta do usu√°rio.

PERGUNTA: {question}

DADOS ESTRUTURADOS (SQL):
{sql_data}

CONTEXTO SEM√ÇNTICO (RAG):
{rag_context}

Gere uma resposta natural, completa e bem formatada que combine ambas as fontes de informa√ß√£o.
Use markdown para formata√ß√£o (negrito, listas, etc).

Resposta:""")
    
    try:
        response = llm.invoke(prompt.format(
            question=question,
            sql_data=json.dumps(sql_data, ensure_ascii=False, indent=2),
            rag_context=rag_response
        ))
        return response.content
    except Exception as e:
        print(f"‚ùå Erro ao combinar respostas: {e}")
        # Fallback: retorna SQL formatado
        return format_sql_results(sql_data, question)
