"""
Servi√ßo H√≠brido: RAG + SQL para responder QUALQUER pergunta sobre produtos.

ESTRAT√âGIA:
1. LLM analisa a pergunta e decide qual ferramenta usar
2. Perguntas estruturadas (filtros, agrega√ß√µes) ‚Üí SQL Tool
3. Perguntas sem√¢nticas (descri√ß√µes, compara√ß√µes) ‚Üí RAG
4. Perguntas complexas ‚Üí Combina ambos
"""

import json
from typing import Any

from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from sqlmodel import Session


def analyze_query_intent(user_question: str) -> dict[str, Any]:
    """
    Usa LLM para analisar a inten√ß√£o da pergunta e decidir qual ferramenta usar.

    Returns:
        {
            "query_type": "sql" | "rag" | "hybrid",
            "needs_filter": bool,
            "filters": {...},
            "semantic_query": str
        }
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.1
    )

    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um analisador de consultas de banco de dados.

Analise a pergunta do usu√°rio e determine:
1. Se precisa de consulta SQL estruturada (filtros, agrega√ß√µes, compara√ß√µes num√©ricas)
2. Se precisa de busca sem√¢ntica RAG (descri√ß√µes, caracter√≠sticas, informa√ß√µes textuais)
3. Se precisa de previs√µes ML (pre√ßos futuros, tend√™ncias, proje√ß√µes)
4. Se precisa de an√°lise de vendas hist√≥ricas (mais vendido, per√≠odos espec√≠ficos)
5. Ou se precisa combinar m√∫ltiplas ferramentas (h√≠brido)

PERGUNTA: {question}

Retorne um JSON com:
{{
    "query_type": "sql" | "rag" | "hybrid" | "ml_prediction" | "sales_analysis",
    "needs_stock_filter": true/false,
    "stock_filter_type": "low" | "high" | "all" | null,
    "needs_category_filter": true/false,
    "category": "categoria" | null,
    "needs_sorting": true/false,
    "sort_by": "stock_asc" | "stock_desc" | "sales_desc" | null,
    "needs_prediction": true/false,
    "prediction_type": "price" | "demand" | null,
    "time_filter": {{"month": "maio" | null, "year": 2025 | null}},
    "semantic_aspect": "descri√ß√£o do que buscar semanticamente" | null,
    "reasoning": "breve explica√ß√£o da decis√£o"
}}

Responda APENAS com o JSON, sem texto adicional.""")

    try:
        response = llm.invoke(prompt.format(question=user_question))
        # Remove markdown code blocks se existirem
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]

        return json.loads(content.strip())
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao analisar intent: {e}")
        # Fallback: usa RAG por padr√£o
        return {
            "query_type": "rag",
            "needs_stock_filter": False,
            "reasoning": "Fallback para RAG devido a erro na an√°lise"
        }


def execute_hybrid_query(user_question: str, db_session: Session) -> str:
    """
    Executa consulta h√≠brida combinando SQL e RAG conforme necess√°rio.

    Args:
        user_question: Pergunta do usu√°rio
        db_session: Sess√£o do banco de dados

    Returns:
        Resposta formatada em linguagem natural
    """
    # 1. Analisa a inten√ß√£o da pergunta
    intent = analyze_query_intent(user_question)
    print(f"üß† Intent detectado: {intent.get('query_type')} - {intent.get('reasoning')}")

    query_type = intent.get("query_type", "rag")

    # 2. Executa an√°lise de vendas hist√≥ricas se necess√°rio
    sales_data = None
    if query_type in ["sales_analysis", "hybrid"] or intent.get("time_filter", {}).get("month"):
        sales_data = execute_sales_analysis(intent, db_session)
        print(f"üìà An√°lise de vendas retornou {len(sales_data) if isinstance(sales_data, list) else 'dados'}")

    # 3. Executa consulta SQL se necess√°rio
    sql_results = None
    if query_type in ["sql", "hybrid"]:
        sql_results = execute_sql_query(intent, db_session)
        print(f"üìä SQL retornou {len(sql_results) if isinstance(sql_results, list) else 'dados'}")

    # 4. Executa previs√µes ML se necess√°rio
    ml_predictions = None
    if query_type in ["ml_prediction", "hybrid"] or intent.get("needs_prediction"):
        ml_predictions = execute_ml_predictions(intent, db_session, sales_data)
        print(f"üéØ ML Predictions retornou dados para {len(ml_predictions) if isinstance(ml_predictions, list) else 0} produtos")

    # 5. Executa RAG se necess√°rio
    rag_response = None
    if query_type in ["rag", "hybrid"]:
        from app.services.rag_service import query_product_catalog_with_google_rag

        # Enriquece contexto com todos os dados dispon√≠veis
        context_data = {}
        if sql_results:
            context_data["produtos"] = sql_results
        if sales_data:
            context_data["vendas"] = sales_data
        if ml_predictions:
            context_data["previsoes"] = ml_predictions

        if context_data:
            enhanced_query = f"{user_question}\n\nDados dispon√≠veis: {json.dumps(context_data, ensure_ascii=False)}"
            rag_response = query_product_catalog_with_google_rag(enhanced_query)
        else:
            rag_response = query_product_catalog_with_google_rag(user_question)

        print(f"ü§ñ RAG respondeu: {rag_response[:100]}...")

    # 6. Combina resultados e gera resposta final
    return format_final_response(
        user_question,
        sql_results,
        rag_response,
        intent,
        sales_data=sales_data,
        ml_predictions=ml_predictions
    )


def execute_sql_query(intent: dict[str, Any], db_session: Session) -> Any:
    """
    Executa consulta SQL baseada no intent analisado.
    """
    from app.services.sql_query_tool import (
        get_products_sorted_by_stock,
        get_stock_statistics,
        query_products_with_filters,
    )

    # Consulta produtos com estoque baixo
    if intent.get("needs_stock_filter") and intent.get("stock_filter_type") == "low":
        return query_products_with_filters(
            db_session,
            estoque_baixo=True,
            categoria=intent.get("category"),
            limit=50
        )

    # Consulta produtos ordenados por estoque
    if intent.get("needs_sorting"):
        order = "asc" if intent.get("sort_by") == "stock_asc" else "desc"
        return get_products_sorted_by_stock(db_session, order=order, limit=20)

    # Estat√≠sticas gerais
    if "estat√≠stica" in intent.get("reasoning", "").lower() or "quantos" in intent.get("reasoning", "").lower():
        return get_stock_statistics(db_session)

    # Fallback: retorna produtos com filtros gerais
    return query_products_with_filters(
        db_session,
        estoque_baixo=intent.get("stock_filter_type") == "low",
        categoria=intent.get("category"),
        limit=50
    )


def execute_sales_analysis(intent: dict[str, Any], db_session: Session) -> Any:
    """
    Executa an√°lise de vendas hist√≥ricas baseada no intent.
    """

    from sqlmodel import func, select

    from app.models.models import Produto, VendasHistoricas

    time_filter = intent.get("time_filter", {})
    month = time_filter.get("month")

    # Mapear nome do m√™s para n√∫mero
    month_map = {
        "janeiro": 1, "fevereiro": 2, "mar√ßo": 3, "abril": 4,
        "maio": 5, "junho": 6, "julho": 7, "agosto": 8,
        "setembro": 9, "outubro": 10, "novembro": 11, "dezembro": 12
    }

    month_num = month_map.get(month.lower()) if month else None

    try:
        # Query: produtos mais vendidos no m√™s espec√≠fico
        query = (
            select(
                Produto.sku,
                Produto.nome,
                func.sum(VendasHistoricas.quantidade).label("total_vendido"),
                func.sum(VendasHistoricas.receita).label("receita_total"),
                func.count(VendasHistoricas.id).label("num_transacoes")
            )
            .join(VendasHistoricas, Produto.id == VendasHistoricas.produto_id)
        )

        # Filtrar por m√™s se especificado
        if month_num:
            query = query.where(func.extract('month', VendasHistoricas.data_venda) == month_num)

        # Agrupar e ordenar
        query = (
            query
            .group_by(Produto.sku, Produto.nome)
            .order_by(func.sum(VendasHistoricas.quantidade).desc())
            .limit(20)
        )

        results = db_session.exec(query).all()

        return [
            {
                "sku": r.sku,
                "nome": r.nome,
                "total_vendido": int(r.total_vendido),
                "receita_total": float(r.receita_total),
                "num_transacoes": int(r.num_transacoes),
                "ticket_medio": float(r.receita_total / r.total_vendido) if r.total_vendido > 0 else 0
            }
            for r in results
        ]
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de vendas: {e}")
        return []


def execute_ml_predictions(intent: dict[str, Any], db_session: Session, sales_data: Any = None) -> Any:
    """
    Executa previs√µes ML para produtos relevantes.
    """
    from app.ml.prediction import predict_prices_for_product

    try:
        # Se tem dados de vendas, pega top produtos
        if sales_data and len(sales_data) > 0:
            top_skus = [item["sku"] for item in sales_data[:5]]  # Top 5
        else:
            # Pega produtos aleat√≥rios
            from sqlmodel import select

            from app.models.models import Produto
            results = db_session.exec(select(Produto.sku).limit(5)).all()
            top_skus = results

        predictions = []
        for sku in top_skus:
            try:
                pred = predict_prices_for_product(sku, days_ahead=14)
                if pred:
                    predictions.append({
                        "sku": sku,
                        "previsoes": pred.get("prices", [])[:7],  # Pr√≥ximos 7 dias
                        "datas": pred.get("dates", [])[:7],
                        "metricas": pred.get("metrics", {}),
                        "tendencia": "alta" if len(pred.get("prices", [])) > 1 and pred["prices"][-1] > pred["prices"][0] else "baixa"
                    })
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao prever {sku}: {e}")
                continue

        return predictions if predictions else None
    except Exception as e:
        print(f"‚ùå Erro nas previs√µes ML: {e}")
        return None


def format_final_response(
    question: str,
    sql_results: Any,
    rag_response: str,
    intent: dict[str, Any],
    sales_data: Any = None,
    ml_predictions: Any = None
) -> str:
    """
    Formata resposta final combinando SQL, RAG, Vendas e ML Predictions.
    """
    # Se tem dados de vendas + previs√µes, usa LLM avan√ßado
    if sales_data or ml_predictions:
        return combine_advanced_response(question, sql_results, rag_response, sales_data, ml_predictions)

    # Se s√≥ tem RAG, retorna direto
    if sql_results is None and rag_response:
        return rag_response

    # Se s√≥ tem SQL, formata os dados
    if sql_results and not rag_response:
        return format_sql_results(sql_results, question)

    # Se tem ambos, usa LLM para combinar
    if sql_results and rag_response:
        return combine_with_llm(question, sql_results, rag_response)

    return "Desculpe, n√£o consegui encontrar informa√ß√µes relevantes para sua pergunta."


def format_sql_results(results: Any, question: str) -> str:
    """
    Formata resultados SQL em linguagem natural.
    Limita a 10 produtos para evitar respostas muito longas.
    """
    # Se √© estat√≠stica
    if isinstance(results, dict) and "total_produtos" in results:
        return (
            f"## Estat√≠sticas do Estoque\n\n"
            f"- Total de produtos: {results['total_produtos']}\n"
            f"- Produtos com estoque baixo: {results['produtos_estoque_baixo']}\n"
            f"- Estoque total: {results['estoque_total_unidades']} unidades\n"
        )

    # Se √© lista de produtos
    if isinstance(results, list):
        if not results:
            return "N√£o encontrei produtos que atendam aos crit√©rios da sua busca."

        # Produtos com estoque baixo
        estoque_baixo = [p for p in results if p.get("estoque_baixo")]
        if estoque_baixo:
            total = len(estoque_baixo)
            limite = 10  # Limita a 10 produtos para n√£o exceder tamanho da coluna

            response = "## Produtos com Estoque Baixo\n\n"
            response += f"Encontrei {total} produto(s) com estoque abaixo do m√≠nimo.\n\n"

            for p in estoque_baixo[:limite]:
                diferenca = p.get("diferenca", 0)
                response += (
                    f"- **{p['nome']}** (SKU: {p['sku']})\n"
                    f"  - Estoque: {p['estoque_atual']}/{p['estoque_minimo']} unidades\n"
                    f"  - Faltam: {abs(diferenca)} unidades\n\n"
                )

            if total > limite:
                response += f"\n*Foram encontrados mais {total - limite} produto(s). Use filtros para refinar a busca.*\n"

            return response

        # Produtos gerais
        total = len(results)
        limite = 10

        response = "## Produtos Encontrados\n\n"
        response += f"Total: {total} produto(s)\n\n"

        for p in results[:limite]:
            response += (
                f"- **{p['nome']}** (SKU: {p['sku']})\n"
                f"  - Estoque: {p['estoque_atual']} unidades\n\n"
            )

        if total > limite:
            response += f"\n*Foram encontrados mais {total - limite} produto(s).*\n"

        return response

    return str(results)


def combine_advanced_response(
    question: str,
    sql_data: Any,
    rag_response: str,
    sales_data: Any,
    ml_predictions: Any
) -> str:
    """
    Combina TODOS os dados (SQL + RAG + Vendas + ML) em resposta natural.
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.4  # Um pouco mais criativo para respostas naturais
    )

    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um assistente inteligente especializado em gest√£o de compras industriais.

Responda √† pergunta do usu√°rio de forma NATURAL, CONVERSACIONAL e BEM FORMATADA.

PERGUNTA: {question}

DADOS DE VENDAS HIST√ìRICAS:
{sales_data}

PREVIS√ïES DE MACHINE LEARNING:
{ml_predictions}

DADOS DE PRODUTOS (SQL):
{sql_data}

CONTEXTO ADICIONAL (RAG):
{rag_context}

REGRAS IMPORTANTES:
- N√ÉO use emojis ou s√≠mbolos especiais
- Use markdown limpo: t√≠tulos (##), listas (-), tabelas
- Use NEGRITO apenas em palavras-chave importantes
- Seja direto, objetivo e profissional
- Tom amig√°vel mas corporativo
- Use tabelas para apresentar m√∫ltiplos dados

INSTRU√á√ïES DE CONTE√öDO:
1. Comece com um resumo direto da resposta
2. Apresente dados em tabelas organizadas
3. Destaque n√∫meros e valores de forma clara
4. Se houver previs√µes ML, mencione tend√™ncias
5. Finalize com recomenda√ß√£o pr√°tica

FORMATO ESPERADO:

## An√°lise de [Tema]

[Resumo direto em 1-2 linhas sobre a resposta]

### Principais Resultados

| Produto | SKU | Vendas | Receita |
|---------|-----|--------|---------|
| Nome 1  | XXX | 100    | R$ XXX  |
| Nome 2  | YYY | 90     | R$ YYY  |

### Insights

- Tend√™ncia principal: [descri√ß√£o]
- Oportunidade identificada: [descri√ß√£o]

### Recomenda√ß√£o

[Recomenda√ß√£o pr√°tica e acion√°vel, 2-3 linhas]

Resposta:""")

    try:
        response = llm.invoke(prompt.format(
            question=question,
            sales_data=json.dumps(sales_data, ensure_ascii=False, indent=2) if sales_data else "N√£o dispon√≠vel",
            ml_predictions=json.dumps(ml_predictions, ensure_ascii=False, indent=2) if ml_predictions else "N√£o dispon√≠vel",
            sql_data=json.dumps(sql_data, ensure_ascii=False, indent=2) if sql_data else "N√£o dispon√≠vel",
            rag_context=rag_response if rag_response else "N√£o dispon√≠vel"
        ))
        return response.content
    except Exception as e:
        print(f"‚ùå Erro ao gerar resposta avan√ßada: {e}")
        # Fallback: formata vendas se dispon√≠vel
        if sales_data:
            return format_sales_results(sales_data, question)
        return "Desculpe, ocorreu um erro ao processar sua pergunta."


def format_sales_results(sales_data: list, question: str) -> str:
    """Formata resultados de vendas de forma visual com tabelas."""
    if not sales_data:
        return "N√£o encontrei dados de vendas para esse per√≠odo."

    # Cabe√ßalho
    response = "## An√°lise de Vendas\n\n"
    response += f"Encontrei {len(sales_data)} produto(s) com dados de vendas.\n\n"

    # Tabela com top 10
    response += "### Principais Produtos\n\n"
    response += "| Posi√ß√£o | Produto | SKU | Vendas | Receita | Ticket M√©dio |\n"
    response += "|---------|---------|-----|--------|---------|-------------|\n"

    for i, item in enumerate(sales_data[:10], 1):
        response += (
            f"| {i} | {item['nome'][:30]} | {item['sku']} | "
            f"{item['total_vendido']} un | "
            f"R$ {item['receita_total']:,.2f} | "
            f"R$ {item['ticket_medio']:.2f} |\n"
        )

    if len(sales_data) > 10:
        response += f"\n*Foram encontrados mais {len(sales_data) - 10} produtos al√©m dos listados acima.*\n"

    # Resumo
    total_vendas = sum(item['total_vendido'] for item in sales_data[:10])
    total_receita = sum(item['receita_total'] for item in sales_data[:10])

    response += "\n### Resumo dos Top 10\n\n"
    response += f"- Total de unidades vendidas: {total_vendas:,}\n"
    response += f"- Receita total: R$ {total_receita:,.2f}\n"

    return response


def combine_with_llm(question: str, sql_data: Any, rag_response: str) -> str:
    """
    Usa LLM para combinar dados SQL e resposta RAG em uma resposta coerente.
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.3
    )

    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um assistente especializado em produtos industriais.

Combine as informa√ß√µes para responder de forma CLARA, OBJETIVA e BEM FORMATADA.

PERGUNTA: {question}

DADOS ESTRUTURADOS (SQL):
{sql_data}

CONTEXTO SEM√ÇNTICO (RAG):
{rag_context}

REGRAS IMPORTANTES:
- N√ÉO use emojis ou s√≠mbolos especiais
- Use markdown limpo: t√≠tulos (##), listas (-), tabelas
- Use NEGRITO apenas em palavras-chave importantes
- Seja direto e objetivo
- Tom profissional mas amig√°vel
- Use tabelas para compara√ß√µes

FORMATO:

## [T√≠tulo da Se√ß√£o]

[Texto explicativo direto e natural]

### Detalhes

| Item | Valor |
|------|-------|
| ...  | ...   |

### Recomenda√ß√£o

[Recomenda√ß√£o pr√°tica em 2-3 linhas]

Resposta:""")

    try:
        response = llm.invoke(prompt.format(
            question=question,
            sql_data=json.dumps(sql_data, ensure_ascii=False, indent=2),
            rag_context=rag_response
        ))
        return response.content
    except Exception as e:
        print(f"‚ùå Erro ao combinar respostas: {e}")
        # Fallback: retorna SQL formatado
        return format_sql_results(sql_data, question)
