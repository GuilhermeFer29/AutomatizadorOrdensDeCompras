"""
Servi√ßo H√≠brido: RAG + SQL para responder QUALQUER pergunta sobre produtos.

ESTRAT√âGIA:
1. LLM analisa a pergunta e decide qual ferramenta usar
2. Perguntas estruturadas (filtros, agrega√ß√µes) ‚Üí SQL Tool
3. Perguntas sem√¢nticas (descri√ß√µes, compara√ß√µes) ‚Üí RAG
4. Perguntas complexas ‚Üí Combina ambos
"""

from typing import Dict, Any
from sqlmodel import Session
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
import json


def analyze_query_intent(user_question: str) -> Dict[str, Any]:
    """
    Usa LLM para analisar a inten√ß√£o da pergunta e decidir qual ferramenta usar.
    
    Returns:
        {
            "query_type": "sql" | "rag" | "hybrid",
            "needs_filter": bool,
            "filters": {...},
            "semantic_query": str
        }
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.1
    )
    
    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um analisador de consultas de banco de dados.

Analise a pergunta do usu√°rio e determine:
1. Se precisa de consulta SQL estruturada (filtros, agrega√ß√µes, compara√ß√µes num√©ricas)
2. Se precisa de busca sem√¢ntica RAG (descri√ß√µes, caracter√≠sticas, informa√ß√µes textuais)
3. Se precisa de previs√µes ML (pre√ßos futuros, tend√™ncias, proje√ß√µes)
4. Se precisa de an√°lise de vendas hist√≥ricas (mais vendido, per√≠odos espec√≠ficos)
5. Ou se precisa combinar m√∫ltiplas ferramentas (h√≠brido)

PERGUNTA: {question}

Retorne um JSON com:
{{
    "query_type": "sql" | "rag" | "hybrid" | "ml_prediction" | "sales_analysis",
    "needs_stock_filter": true/false,
    "stock_filter_type": "low" | "high" | "all" | null,
    "needs_category_filter": true/false,
    "category": "categoria" | null,
    "needs_sorting": true/false,
    "sort_by": "stock_asc" | "stock_desc" | "sales_desc" | null,
    "needs_prediction": true/false,
    "prediction_type": "price" | "demand" | null,
    "time_filter": {{"month": "maio" | null, "year": 2025 | null}},
    "semantic_aspect": "descri√ß√£o do que buscar semanticamente" | null,
    "reasoning": "breve explica√ß√£o da decis√£o"
}}

Responda APENAS com o JSON, sem texto adicional.""")
    
    try:
        response = llm.invoke(prompt.format(question=user_question))
        # Remove markdown code blocks se existirem
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        
        return json.loads(content.strip())
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao analisar intent: {e}")
        # Fallback: usa RAG por padr√£o
        return {
            "query_type": "rag",
            "needs_stock_filter": False,
            "reasoning": "Fallback para RAG devido a erro na an√°lise"
        }


def execute_hybrid_query(user_question: str, db_session: Session) -> str:
    """
    Executa consulta h√≠brida combinando SQL e RAG conforme necess√°rio.
    
    Args:
        user_question: Pergunta do usu√°rio
        db_session: Sess√£o do banco de dados
        
    Returns:
        Resposta formatada em linguagem natural
    """
    # 1. Analisa a inten√ß√£o da pergunta
    intent = analyze_query_intent(user_question)
    print(f"üß† Intent detectado: {intent.get('query_type')} - {intent.get('reasoning')}")
    
    query_type = intent.get("query_type", "rag")
    
    # 2. Executa an√°lise de vendas hist√≥ricas se necess√°rio
    sales_data = None
    if query_type in ["sales_analysis", "hybrid"] or intent.get("time_filter", {}).get("month"):
        sales_data = execute_sales_analysis(intent, db_session)
        print(f"üìà An√°lise de vendas retornou {len(sales_data) if isinstance(sales_data, list) else 'dados'}")
    
    # 3. Executa consulta SQL se necess√°rio
    sql_results = None
    if query_type in ["sql", "hybrid"]:
        sql_results = execute_sql_query(intent, db_session)
        print(f"üìä SQL retornou {len(sql_results) if isinstance(sql_results, list) else 'dados'}")
    
    # 4. Executa previs√µes ML se necess√°rio
    ml_predictions = None
    if query_type in ["ml_prediction", "hybrid"] or intent.get("needs_prediction"):
        ml_predictions = execute_ml_predictions(intent, db_session, sales_data)
        print(f"üéØ ML Predictions retornou dados para {len(ml_predictions) if isinstance(ml_predictions, list) else 0} produtos")
    
    # 5. Executa RAG se necess√°rio
    rag_response = None
    if query_type in ["rag", "hybrid"]:
        from app.services.rag_service import query_product_catalog_with_google_rag
        
        # Enriquece contexto com todos os dados dispon√≠veis
        context_data = {}
        if sql_results:
            context_data["produtos"] = sql_results
        if sales_data:
            context_data["vendas"] = sales_data
        if ml_predictions:
            context_data["previsoes"] = ml_predictions
        
        if context_data:
            enhanced_query = f"{user_question}\n\nDados dispon√≠veis: {json.dumps(context_data, ensure_ascii=False)}"
            rag_response = query_product_catalog_with_google_rag(enhanced_query)
        else:
            rag_response = query_product_catalog_with_google_rag(user_question)
        
        print(f"ü§ñ RAG respondeu: {rag_response[:100]}...")
    
    # 6. Combina resultados e gera resposta final
    return format_final_response(
        user_question, 
        sql_results, 
        rag_response, 
        intent,
        sales_data=sales_data,
        ml_predictions=ml_predictions
    )


def execute_sql_query(intent: Dict[str, Any], db_session: Session) -> Any:
    """
    Executa consulta SQL baseada no intent analisado.
    """
    from app.services.sql_query_tool import (
        query_products_with_filters,
        get_stock_statistics,
        get_products_sorted_by_stock
    )
    
    # Consulta produtos com estoque baixo
    if intent.get("needs_stock_filter") and intent.get("stock_filter_type") == "low":
        return query_products_with_filters(
            db_session,
            estoque_baixo=True,
            categoria=intent.get("category"),
            limit=50
        )
    
    # Consulta produtos ordenados por estoque
    if intent.get("needs_sorting"):
        order = "asc" if intent.get("sort_by") == "stock_asc" else "desc"
        return get_products_sorted_by_stock(db_session, order=order, limit=20)
    
    # Estat√≠sticas gerais
    if "estat√≠stica" in intent.get("reasoning", "").lower() or "quantos" in intent.get("reasoning", "").lower():
        return get_stock_statistics(db_session)
    
    # Fallback: retorna produtos com filtros gerais
    return query_products_with_filters(
        db_session,
        estoque_baixo=intent.get("stock_filter_type") == "low",
        categoria=intent.get("category"),
        limit=50
    )


def execute_sales_analysis(intent: Dict[str, Any], db_session: Session) -> Any:
    """
    Executa an√°lise de vendas hist√≥ricas baseada no intent.
    """
    from sqlmodel import select, func
    from app.models.models import VendasHistoricas, Produto
    from datetime import datetime
    
    time_filter = intent.get("time_filter", {})
    month = time_filter.get("month")
    
    # Mapear nome do m√™s para n√∫mero
    month_map = {
        "janeiro": 1, "fevereiro": 2, "mar√ßo": 3, "abril": 4,
        "maio": 5, "junho": 6, "julho": 7, "agosto": 8,
        "setembro": 9, "outubro": 10, "novembro": 11, "dezembro": 12
    }
    
    month_num = month_map.get(month.lower()) if month else None
    
    try:
        # Query: produtos mais vendidos no m√™s espec√≠fico
        query = (
            select(
                Produto.sku,
                Produto.nome,
                func.sum(VendasHistoricas.quantidade).label("total_vendido"),
                func.sum(VendasHistoricas.receita).label("receita_total"),
                func.count(VendasHistoricas.id).label("num_transacoes")
            )
            .join(VendasHistoricas, Produto.id == VendasHistoricas.produto_id)
        )
        
        # Filtrar por m√™s se especificado
        if month_num:
            query = query.where(func.month(VendasHistoricas.data) == month_num)
        
        # Agrupar e ordenar
        query = (
            query
            .group_by(Produto.sku, Produto.nome)
            .order_by(func.sum(VendasHistoricas.quantidade).desc())
            .limit(20)
        )
        
        results = db_session.exec(query).all()
        
        return [
            {
                "sku": r.sku,
                "nome": r.nome,
                "total_vendido": int(r.total_vendido),
                "receita_total": float(r.receita_total),
                "num_transacoes": int(r.num_transacoes),
                "ticket_medio": float(r.receita_total / r.total_vendido) if r.total_vendido > 0 else 0
            }
            for r in results
        ]
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de vendas: {e}")
        return []


def execute_ml_predictions(intent: Dict[str, Any], db_session: Session, sales_data: Any = None) -> Any:
    """
    Executa previs√µes ML para produtos relevantes.
    """
    from app.ml.prediction import predict_prices
    
    try:
        # Se tem dados de vendas, pega top produtos
        if sales_data and len(sales_data) > 0:
            top_skus = [item["sku"] for item in sales_data[:5]]  # Top 5
        else:
            # Pega produtos aleat√≥rios
            from app.models.models import Produto
            from sqlmodel import select
            results = db_session.exec(select(Produto.sku).limit(5)).all()
            top_skus = results
        
        predictions = []
        for sku in top_skus:
            try:
                pred = predict_prices(sku, days_ahead=14)
                if pred:
                    predictions.append({
                        "sku": sku,
                        "previsoes": pred.get("prices", [])[:7],  # Pr√≥ximos 7 dias
                        "datas": pred.get("dates", [])[:7],
                        "metricas": pred.get("metrics", {}),
                        "tendencia": "alta" if len(pred.get("prices", [])) > 1 and pred["prices"][-1] > pred["prices"][0] else "baixa"
                    })
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao prever {sku}: {e}")
                continue
        
        return predictions if predictions else None
    except Exception as e:
        print(f"‚ùå Erro nas previs√µes ML: {e}")
        return None


def format_final_response(
    question: str,
    sql_results: Any,
    rag_response: str,
    intent: Dict[str, Any],
    sales_data: Any = None,
    ml_predictions: Any = None
) -> str:
    """
    Formata resposta final combinando SQL, RAG, Vendas e ML Predictions.
    """
    # Se tem dados de vendas + previs√µes, usa LLM avan√ßado
    if sales_data or ml_predictions:
        return combine_advanced_response(question, sql_results, rag_response, sales_data, ml_predictions)
    
    # Se s√≥ tem RAG, retorna direto
    if sql_results is None and rag_response:
        return rag_response
    
    # Se s√≥ tem SQL, formata os dados
    if sql_results and not rag_response:
        return format_sql_results(sql_results, question)
    
    # Se tem ambos, usa LLM para combinar
    if sql_results and rag_response:
        return combine_with_llm(question, sql_results, rag_response)
    
    return "Desculpe, n√£o consegui encontrar informa√ß√µes relevantes para sua pergunta."


def format_sql_results(results: Any, question: str) -> str:
    """
    Formata resultados SQL em linguagem natural.
    Limita a 10 produtos para evitar respostas muito longas.
    """
    # Se √© estat√≠stica
    if isinstance(results, dict) and "total_produtos" in results:
        return (
            f"üìä **Estat√≠sticas do Estoque:**\n\n"
            f"‚Ä¢ Total de produtos: {results['total_produtos']}\n"
            f"‚Ä¢ Produtos com estoque baixo: {results['produtos_estoque_baixo']}\n"
            f"‚Ä¢ Estoque total: {results['estoque_total_unidades']} unidades\n"
        )
    
    # Se √© lista de produtos
    if isinstance(results, list):
        if not results:
            return "N√£o encontrei produtos que atendam aos crit√©rios da sua busca."
        
        # Produtos com estoque baixo
        estoque_baixo = [p for p in results if p.get("estoque_baixo")]
        if estoque_baixo:
            total = len(estoque_baixo)
            limite = 10  # Limita a 10 produtos para n√£o exceder tamanho da coluna
            
            response = f"‚ö†Ô∏è **Encontrei {total} produto(s) com estoque baixo:**\n\n"
            
            for p in estoque_baixo[:limite]:
                diferenca = p.get("diferenca", 0)
                response += (
                    f"‚Ä¢ **{p['nome']}** (SKU: {p['sku']})\n"
                    f"  - Estoque: {p['estoque_atual']}/{p['estoque_minimo']} unidades\n"
                    f"  - Faltam: {abs(diferenca)} unidades\n\n"
                )
            
            if total > limite:
                response += f"\n_...e mais {total - limite} produto(s). Use filtros para refinar a busca._"
            
            return response
        
        # Produtos gerais
        total = len(results)
        limite = 10
        
        response = f"üì¶ **Encontrei {total} produto(s):**\n\n"
        for p in results[:limite]:
            response += (
                f"‚Ä¢ **{p['nome']}** (SKU: {p['sku']})\n"
                f"  - Estoque: {p['estoque_atual']} unidades\n\n"
            )
        
        if total > limite:
            response += f"\n_...e mais {total - limite} produto(s)._"
        
        return response
    
    return str(results)


def combine_advanced_response(
    question: str,
    sql_data: Any,
    rag_response: str,
    sales_data: Any,
    ml_predictions: Any
) -> str:
    """
    Combina TODOS os dados (SQL + RAG + Vendas + ML) em resposta natural.
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.4  # Um pouco mais criativo para respostas naturais
    )
    
    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um assistente inteligente especializado em gest√£o de compras industriais.

Responda √† pergunta do usu√°rio de forma NATURAL, CONVERSACIONAL e COMPLETA, combinando todas as fontes de informa√ß√£o dispon√≠veis.

PERGUNTA: {question}

üìä DADOS DE VENDAS HIST√ìRICAS:
{sales_data}

üéØ PREVIS√ïES DE MACHINE LEARNING:
{ml_predictions}

üì¶ DADOS DE PRODUTOS (SQL):
{sql_data}

üìö CONTEXTO ADICIONAL (RAG):
{rag_context}

INSTRU√á√ïES IMPORTANTES:
1. Responda de forma natural e conversacional, como se estivesse falando com um colega
2. Use os dados de vendas para identificar produtos mais populares
3. Use as previs√µes ML para dar insights sobre tend√™ncias futuras
4. Combine tudo em uma narrativa coerente
5. Use emojis e formata√ß√£o markdown para tornar a resposta mais agrad√°vel
6. Se houver tend√™ncias de pre√ßo, mencione explicitamente
7. Seja espec√≠fico com n√∫meros, datas e valores
8. Finalize com uma recomenda√ß√£o ou insight √∫til

Resposta:""")
    
    try:
        response = llm.invoke(prompt.format(
            question=question,
            sales_data=json.dumps(sales_data, ensure_ascii=False, indent=2) if sales_data else "N√£o dispon√≠vel",
            ml_predictions=json.dumps(ml_predictions, ensure_ascii=False, indent=2) if ml_predictions else "N√£o dispon√≠vel",
            sql_data=json.dumps(sql_data, ensure_ascii=False, indent=2) if sql_data else "N√£o dispon√≠vel",
            rag_context=rag_response if rag_response else "N√£o dispon√≠vel"
        ))
        return response.content
    except Exception as e:
        print(f"‚ùå Erro ao gerar resposta avan√ßada: {e}")
        # Fallback: formata vendas se dispon√≠vel
        if sales_data:
            return format_sales_results(sales_data, question)
        return "Desculpe, ocorreu um erro ao processar sua pergunta."


def format_sales_results(sales_data: list, question: str) -> str:
    """Formata resultados de vendas de forma visual."""
    if not sales_data:
        return "N√£o encontrei dados de vendas para esse per√≠odo."
    
    response = "üìà **An√°lise de Vendas:**\n\n"
    
    for i, item in enumerate(sales_data[:10], 1):
        response += (
            f"{i}. **{item['nome']}** (SKU: {item['sku']})\n"
            f"   ‚Ä¢ Total vendido: {item['total_vendido']} unidades\n"
            f"   ‚Ä¢ Receita: R$ {item['receita_total']:.2f}\n"
            f"   ‚Ä¢ Ticket m√©dio: R$ {item['ticket_medio']:.2f}\n\n"
        )
    
    if len(sales_data) > 10:
        response += f"\n_...e mais {len(sales_data) - 10} produtos._"
    
    return response


def combine_with_llm(question: str, sql_data: Any, rag_response: str) -> str:
    """
    Usa LLM para combinar dados SQL e resposta RAG em uma resposta coerente.
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.3
    )
    
    prompt = ChatPromptTemplate.from_template("""Voc√™ √© um assistente especializado em produtos industriais.

Combine as informa√ß√µes estruturadas do banco de dados com o contexto sem√¢ntico para responder a pergunta do usu√°rio.

PERGUNTA: {question}

DADOS ESTRUTURADOS (SQL):
{sql_data}

CONTEXTO SEM√ÇNTICO (RAG):
{rag_context}

Gere uma resposta natural, completa e bem formatada que combine ambas as fontes de informa√ß√£o.
Use markdown para formata√ß√£o (negrito, listas, etc).

Resposta:""")
    
    try:
        response = llm.invoke(prompt.format(
            question=question,
            sql_data=json.dumps(sql_data, ensure_ascii=False, indent=2),
            rag_context=rag_response
        ))
        return response.content
    except Exception as e:
        print(f"‚ùå Erro ao combinar respostas: {e}")
        # Fallback: retorna SQL formatado
        return format_sql_results(sql_data, question)
