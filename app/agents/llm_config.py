"""
ConfiguraÃ§Ã£o Centralizada do LLM Gemini.

Este mÃ³dulo fornece uma funÃ§Ã£o Ãºnica para configurar e retornar instÃ¢ncias
do modelo Gemini, garantindo consistÃªncia em todo o projeto e facilitando
manutenÃ§Ã£o futura.

Autor: Sistema de AutomaÃ§Ã£o de Compras
Data: 2025-10-10
"""

import os
from typing import Optional
from agno.models.google import Gemini


def get_gemini_llm(
    temperature: float = 0.3,
    model_id: str = "models/gemini-2.5-flash-latest"
) -> Gemini:
    """
    Configura e retorna uma instÃ¢ncia do modelo Google Gemini.
    
    Esta Ã© a ÃšNICA funÃ§Ã£o que deve ser usada para criar instÃ¢ncias do LLM
    em todo o projeto. Isso garante:
    - ConfiguraÃ§Ã£o consistente em todos os agentes
    - Carregamento centralizado da API key
    - FÃ¡cil manutenÃ§Ã£o e atualizaÃ§Ã£o de versÃµes
    - ValidaÃ§Ã£o adequada de variÃ¡veis de ambiente
    
    Args:
        temperature: Controla a aleatoriedade das respostas (0.0 = determinÃ­stico, 1.0 = criativo).
                    PadrÃ£o: 0.3 (bom para tarefas analÃ­ticas)
        model_id: ID do modelo Gemini a ser usado.
                 PadrÃ£o: "models/gemini-2.5-flash-latest" (mais recente e estÃ¡vel)
                 Alternativas:
                 - "models/gemini-2.5-flash-latest" (mais rÃ¡pido, menos preciso)
                 - "models/gemini-2.5-pro-latest" (versÃ£o anterior)
    
    Returns:
        Gemini: InstÃ¢ncia configurada do modelo Gemini pronta para uso.
    
    Raises:
        ValueError: Se a variÃ¡vel de ambiente GOOGLE_API_KEY nÃ£o estiver configurada.
    
    Example:
        ```python
        from app.agents.llm_config import get_gemini_llm
        from agno.agent import Agent
        
        # Obter modelo configurado
        llm = get_gemini_llm()
        
        # Usar em um agente
        agent = Agent(
            model=llm,
            instructions="VocÃª Ã© um assistente especializado."
        )
        ```
    
    Notas:
        - A API key deve ser definida no arquivo .env: GOOGLE_API_KEY=sua_chave_aqui
        - Obtenha sua chave em: https://aistudio.google.com/app/apikey
        - O modelo Gemini 2.5 Flash suporta:
          * Contexto de atÃ© 1M tokens
          * Multimodal (texto, imagem, Ã¡udio)
          * Function calling avanÃ§ado
          * JSON mode nativo
    """
    # Carrega API key do ambiente
    api_key = os.getenv("GOOGLE_API_KEY")
    
    # ValidaÃ§Ã£o crÃ­tica: sem API key = sem funcionamento
    if not api_key:
        raise ValueError(
            "âŒ ERRO CRÃTICO: A variÃ¡vel de ambiente 'GOOGLE_API_KEY' nÃ£o estÃ¡ configurada.\n"
            "\n"
            "Por favor, adicione-a ao seu arquivo .env:\n"
            "  GOOGLE_API_KEY=sua_chave_aqui\n"
            "\n"
            "Obtenha sua chave gratuita em:\n"
            "  https://aistudio.google.com/app/apikey\n"
            "\n"
            "ApÃ³s adicionar, reinicie a aplicaÃ§Ã£o com:\n"
            "  docker-compose restart api worker\n"
        )
    
    # Log de configuraÃ§Ã£o (Ãºtil para debug)
    masked_key = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "***"
    print(f"ğŸ¤– Gemini LLM configurado: {model_id} (temp={temperature}, key={masked_key})")
    
    # Cria e retorna instÃ¢ncia configurada
    return Gemini(
        id=model_id,
        api_key=api_key,
        temperature=temperature,
        # ConfiguraÃ§Ãµes adicionais (podem ser expandidas conforme necessÃ¡rio)
        # max_tokens=None,  # Usa o mÃ¡ximo do modelo
        # top_p=0.95,       # Nucleus sampling
        # top_k=40,         # Top-k sampling
    )


def get_gemini_for_nlu() -> Gemini:
    """
    Retorna uma instÃ¢ncia do Gemini otimizada para tarefas de NLU (Natural Language Understanding).
    
    ConfiguraÃ§Ã£o especializada:
    - Temperature baixa (0.1) para respostas mais determinÃ­sticas
    - Ideal para extraÃ§Ã£o de entidades e classificaÃ§Ã£o de intenÃ§Ãµes
    
    Returns:
        Gemini: InstÃ¢ncia otimizada para NLU.
    """
    return get_gemini_llm(temperature=0.1)


def get_gemini_for_creative() -> Gemini:
    """
    Retorna uma instÃ¢ncia do Gemini otimizada para tarefas criativas.
    
    ConfiguraÃ§Ã£o especializada:
    - Temperature alta (0.7) para respostas mais variadas
    - Ideal para geraÃ§Ã£o de relatÃ³rios e anÃ¡lises narrativas
    
    Returns:
        Gemini: InstÃ¢ncia otimizada para criaÃ§Ã£o de conteÃºdo.
    """
    return get_gemini_llm(temperature=0.7)


# ValidaÃ§Ã£o ao importar o mÃ³dulo
if __name__ == "__main__":
    print("ğŸ§ª Testando configuraÃ§Ã£o do Gemini LLM...")
    
    try:
        llm = get_gemini_llm()
        print(f"âœ… Sucesso! Modelo configurado: {llm.id}")
        print(f"   Temperature: {llm.temperature}")
        print(f"   API Key: {'âœ“ Configurada' if llm.api_key else 'âœ— Ausente'}")
    except ValueError as e:
        print(f"âŒ Erro: {e}")
    except Exception as e:
        print(f"âŒ Erro inesperado: {e}")
