"""
Gemini Model Fallback Manager - Gerenciamento autom√°tico de fallback entre modelos.

Este m√≥dulo implementa um sistema de fallback que:
1. Tenta o modelo prim√°rio (gemini-2.5-flash)
2. Em caso de erro 429 (rate limit), tenta modelos alternativos
3. Usa retry com exponential backoff
4. Faz log de todas as trocas de modelo

MODELOS NA CHAIN DE FALLBACK (em ordem de prioridade):
======================================================
1. gemini-2.5-flash   - Principal (mais novo, r√°pido)
2. gemini-2.0-flash   - Flash est√°vel 2.0
3. gemini-1.5-flash   - Flash legacy 1.5
4. gemini-1.5-pro     - Pro model (mais quota, mais lento)

Uso:
    from app.agents.gemini_fallback import get_model_with_fallback, run_with_fallback

    # Obter modelo com fallback autom√°tico
    model = get_model_with_fallback(temperature=0.3)

    # Executar fun√ß√£o com retry e fallback
    result = run_with_fallback(agent.run, "Sua mensagem aqui")
"""

import logging
import os
import time
from collections.abc import Callable
from functools import wraps
from typing import Any

from agno.models.google import Gemini

logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURA√á√ÉO DA CHAIN DE FALLBACK
# ============================================================================

# Modelos em ordem de prefer√™ncia (modelos v√°lidos do Gemini)
# Nota: Os modelos devem existir na API - verificar em https://ai.google.dev/gemini-api/docs/models/gemini
MODEL_FALLBACK_CHAIN = [
    "gemini-2.5-flash",        # Primary: Newest flash model
    "gemini-2.5-flash-lite",   # Secondary: Lite version
    "gemini-3-flash",          # Tertiary: Next gen flash
]

# Configura√ß√µes de retry
MAX_RETRIES_PER_MODEL = 2
INITIAL_BACKOFF_SECONDS = 1
BACKOFF_MULTIPLIER = 2
MAX_BACKOFF_SECONDS = 8


# ============================================================================
# GERENCIADOR DE FALLBACK
# ============================================================================

class GeminiFallbackManager:
    """
    Gerencia fallback autom√°tico entre modelos Gemini quando ocorrem erros de rate limit.

    Mant√©m estado do modelo atual e hist√≥rico de erros para decis√µes inteligentes.
    """

    _instance = None  # Singleton para manter estado global

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self.model_chain = MODEL_FALLBACK_CHAIN.copy()
        self.current_index = 0
        self.api_key = os.getenv("GOOGLE_API_KEY")
        self.last_switch_time = 0
        self.error_counts = {model: 0 for model in self.model_chain}
        self._initialized = True

        logger.info(f"üîÑ GeminiFallbackManager inicializado com {len(self.model_chain)} modelos")

    @property
    def current_model_id(self) -> str:
        """Retorna o ID do modelo atual."""
        return self.model_chain[self.current_index]

    def get_model(self, temperature: float = 0.3) -> Gemini:
        """
        Retorna inst√¢ncia do modelo atual na chain de fallback.

        Args:
            temperature: Temperatura para o modelo (0.0 = determin√≠stico, 1.0 = criativo)

        Returns:
            Gemini: Inst√¢ncia configurada do modelo atual
        """
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY n√£o configurada")

        model_id = self.current_model_id
        logger.info(f"ü§ñ Usando modelo: {model_id} (index {self.current_index}/{len(self.model_chain)-1})")

        return Gemini(
            id=model_id,
            api_key=self.api_key,
            temperature=temperature,
        )

    def switch_to_next_model(self) -> bool:
        """
        Alterna para o pr√≥ximo modelo na chain de fallback.

        Returns:
            bool: True se conseguiu alternar, False se n√£o h√° mais modelos
        """
        if self.current_index >= len(self.model_chain) - 1:
            logger.error("‚ùå Todos os modelos na chain de fallback esgotaram quota!")
            return False

        old_model = self.current_model_id
        self.current_index += 1
        new_model = self.current_model_id
        self.last_switch_time = time.time()

        logger.warning(f"‚ö†Ô∏è Fallback: {old_model} -> {new_model} (rate limit)")
        print(f"‚ö†Ô∏è Modelo {old_model} com rate limit. Alternando para {new_model}")

        return True

    def reset_to_primary(self) -> None:
        """Reseta para o modelo prim√°rio (usar ap√≥s per√≠odo de cooldown)."""
        if self.current_index > 0:
            old_model = self.current_model_id
            self.current_index = 0
            logger.info(f"üîÑ Resetando para modelo prim√°rio: {old_model} -> {self.current_model_id}")

    def should_try_primary(self) -> bool:
        """
        Verifica se deve tentar voltar ao modelo prim√°rio.
        Retorna True se passou tempo suficiente desde o √∫ltimo fallback.
        """
        # Se j√° est√° no prim√°rio, n√£o precisa
        if self.current_index == 0:
            return False

        # Cooldown de 5 minutos antes de tentar prim√°rio novamente
        cooldown_seconds = 300
        elapsed = time.time() - self.last_switch_time

        if elapsed > cooldown_seconds:
            logger.info(f"‚è∞ Cooldown de {cooldown_seconds}s passou. Tentando modelo prim√°rio...")
            return True

        return False

    def record_error(self, model_id: str) -> None:
        """Registra erro para um modelo espec√≠fico."""
        if model_id in self.error_counts:
            self.error_counts[model_id] += 1
            logger.debug(f"üìä Erros em {model_id}: {self.error_counts[model_id]}")


# ============================================================================
# FUN√á√ïES DE CONVENI√äNCIA
# ============================================================================

# Inst√¢ncia global do gerenciador
_fallback_manager: GeminiFallbackManager | None = None


def get_fallback_manager() -> GeminiFallbackManager:
    """Retorna a inst√¢ncia singleton do gerenciador de fallback."""
    global _fallback_manager
    if _fallback_manager is None:
        _fallback_manager = GeminiFallbackManager()
    return _fallback_manager


def get_model_with_fallback(temperature: float = 0.3) -> Gemini:
    """
    Retorna modelo Gemini atual da chain de fallback.

    Esta fun√ß√£o √© o ponto de entrada principal para obter um modelo.
    O modelo retornado depende do estado atual da chain de fallback.

    Args:
        temperature: Temperatura do modelo (padr√£o: 0.3)

    Returns:
        Gemini: Inst√¢ncia do modelo atual
    """
    manager = get_fallback_manager()

    # Tentar voltar ao prim√°rio ap√≥s cooldown
    if manager.should_try_primary():
        manager.reset_to_primary()

    return manager.get_model(temperature)


def is_rate_limit_error(exception: Exception) -> bool:
    """
    Verifica se uma exce√ß√£o √© um erro de rate limit (429).

    Args:
        exception: Exce√ß√£o a ser verificada

    Returns:
        bool: True se √© erro 429
    """
    error_msg = str(exception).lower()

    # Checar por indicadores de rate limit
    rate_limit_indicators = [
        "429",
        "rate limit",
        "rate_limit",
        "quota exceeded",
        "resource has been exhausted",
        "too many requests",
        "resourceexhausted",
    ]

    return any(indicator in error_msg for indicator in rate_limit_indicators)


def run_with_fallback(
    func: Callable,
    *args,
    max_retries: int = MAX_RETRIES_PER_MODEL,
    **kwargs
) -> Any:
    """
    Executa uma fun√ß√£o com retry autom√°tico e fallback de modelo em caso de 429.

    Esta fun√ß√£o:
    1. Tenta executar a fun√ß√£o passada
    2. Em caso de erro 429, faz retry com backoff exponencial
    3. Se esgotar retries, alterna para pr√≥ximo modelo na chain
    4. Repete at√© sucesso ou esgotar todos os modelos

    Args:
        func: Fun√ß√£o a ser executada (ex: agent.run)
        *args: Argumentos posicionais para a fun√ß√£o
        max_retries: M√°ximo de retries por modelo antes de fazer fallback
        **kwargs: Argumentos nomeados para a fun√ß√£o

    Returns:
        Resultado da fun√ß√£o executada

    Raises:
        Exception: Re-levanta a √∫ltima exce√ß√£o se todos os modelos falharem
    """
    manager = get_fallback_manager()
    last_exception = None

    # Tentar voltar ao prim√°rio se cooldown passou
    if manager.should_try_primary():
        manager.reset_to_primary()

    # Loop atrav√©s dos modelos na chain
    while True:
        current_model = manager.current_model_id

        # Retry loop para o modelo atual
        for retry in range(max_retries):
            try:
                result = func(*args, **kwargs)

                # Sucesso! Resetar contador de erros do modelo
                manager.error_counts[current_model] = 0
                return result

            except Exception as e:
                last_exception = e

                if is_rate_limit_error(e):
                    manager.record_error(current_model)

                    if retry < max_retries - 1:
                        # Backoff exponencial antes de retry
                        backoff = min(
                            INITIAL_BACKOFF_SECONDS * (BACKOFF_MULTIPLIER ** retry),
                            MAX_BACKOFF_SECONDS
                        )
                        logger.warning(
                            f"‚è≥ Rate limit em {current_model}. "
                            f"Retry {retry + 1}/{max_retries} em {backoff}s..."
                        )
                        time.sleep(backoff)
                    else:
                        # Esgotar retries para este modelo, tentar pr√≥ximo
                        logger.warning(
                            f"‚ùå Esgotaram {max_retries} retries em {current_model}. "
                            f"Tentando fallback..."
                        )
                else:
                    # Erro n√£o relacionado a rate limit, re-levantar imediatamente
                    logger.error(f"‚ùå Erro n√£o-related a rate limit: {e}")
                    raise

        # Tentar pr√≥ximo modelo na chain
        if not manager.switch_to_next_model():
            # N√£o h√° mais modelos, re-levantar √∫ltima exce√ß√£o
            logger.error("üíÄ Todos os modelos na chain de fallback falharam!")
            raise last_exception


# ============================================================================
# DECORATOR PARA FUN√á√ïES COM FALLBACK AUTOM√ÅTICO
# ============================================================================

def with_model_fallback(max_retries: int = MAX_RETRIES_PER_MODEL):
    """
    Decorator que adiciona retry com fallback autom√°tico a uma fun√ß√£o.

    Uso:
        @with_model_fallback(max_retries=3)
        def minha_funcao_com_llm(prompt):
            agent = Agent(model=get_model_with_fallback())
            return agent.run(prompt)
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            return run_with_fallback(func, *args, max_retries=max_retries, **kwargs)
        return wrapper
    return decorator

# Testes movidos para tests/test_gemini_fallback.py
