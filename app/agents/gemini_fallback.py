"""
Gemini Model Fallback Manager - Gerenciamento automÃ¡tico de fallback entre modelos.

Este mÃ³dulo implementa um sistema de fallback que:
1. Tenta o modelo primÃ¡rio (gemini-2.5-flash)
2. Em caso de erro 429 (rate limit), tenta modelos alternativos
3. Usa retry com exponential backoff
4. Faz log de todas as trocas de modelo

MODELOS NA CHAIN DE FALLBACK (em ordem de prioridade):
======================================================
1. gemini-2.5-flash   - Principal (mais novo, rÃ¡pido)
2. gemini-2.0-flash   - Flash estÃ¡vel 2.0
3. gemini-1.5-flash   - Flash legacy 1.5
4. gemini-1.5-pro     - Pro model (mais quota, mais lento)

Uso:
    from app.agents.gemini_fallback import get_model_with_fallback, run_with_fallback
    
    # Obter modelo com fallback automÃ¡tico
    model = get_model_with_fallback(temperature=0.3)
    
    # Executar funÃ§Ã£o com retry e fallback
    result = run_with_fallback(agent.run, "Sua mensagem aqui")
"""

import os
import time
import logging
from typing import Callable, Any, List, Optional
from functools import wraps

from agno.models.google import Gemini

logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURAÃ‡ÃƒO DA CHAIN DE FALLBACK
# ============================================================================

# Modelos em ordem de preferÃªncia (modelos vÃ¡lidos do Gemini)
# Nota: Os modelos devem existir na API - verificar em https://ai.google.dev/gemini-api/docs/models/gemini
MODEL_FALLBACK_CHAIN = [
    "gemini-2.5-flash",        # Primary: Newest flash model
    "gemini-2.5-flash-lite",   # Secondary: Lite version
    "gemini-3-flash",          # Tertiary: Next gen flash
]

# ConfiguraÃ§Ãµes de retry
MAX_RETRIES_PER_MODEL = 2
INITIAL_BACKOFF_SECONDS = 1
BACKOFF_MULTIPLIER = 2
MAX_BACKOFF_SECONDS = 8


# ============================================================================
# GERENCIADOR DE FALLBACK
# ============================================================================

class GeminiFallbackManager:
    """
    Gerencia fallback automÃ¡tico entre modelos Gemini quando ocorrem erros de rate limit.
    
    MantÃ©m estado do modelo atual e histÃ³rico de erros para decisÃµes inteligentes.
    """
    
    _instance = None  # Singleton para manter estado global
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self.model_chain = MODEL_FALLBACK_CHAIN.copy()
        self.current_index = 0
        self.api_key = os.getenv("GOOGLE_API_KEY")
        self.last_switch_time = 0
        self.error_counts = {model: 0 for model in self.model_chain}
        self._initialized = True
        
        logger.info(f"ðŸ”„ GeminiFallbackManager inicializado com {len(self.model_chain)} modelos")
    
    @property
    def current_model_id(self) -> str:
        """Retorna o ID do modelo atual."""
        return self.model_chain[self.current_index]
    
    def get_model(self, temperature: float = 0.3) -> Gemini:
        """
        Retorna instÃ¢ncia do modelo atual na chain de fallback.
        
        Args:
            temperature: Temperatura para o modelo (0.0 = determinÃ­stico, 1.0 = criativo)
            
        Returns:
            Gemini: InstÃ¢ncia configurada do modelo atual
        """
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY nÃ£o configurada")
        
        model_id = self.current_model_id
        logger.info(f"ðŸ¤– Usando modelo: {model_id} (index {self.current_index}/{len(self.model_chain)-1})")
        
        return Gemini(
            id=model_id,
            api_key=self.api_key,
            temperature=temperature,
        )
    
    def switch_to_next_model(self) -> bool:
        """
        Alterna para o prÃ³ximo modelo na chain de fallback.
        
        Returns:
            bool: True se conseguiu alternar, False se nÃ£o hÃ¡ mais modelos
        """
        if self.current_index >= len(self.model_chain) - 1:
            logger.error("âŒ Todos os modelos na chain de fallback esgotaram quota!")
            return False
        
        old_model = self.current_model_id
        self.current_index += 1
        new_model = self.current_model_id
        self.last_switch_time = time.time()
        
        logger.warning(f"âš ï¸ Fallback: {old_model} -> {new_model} (rate limit)")
        print(f"âš ï¸ Modelo {old_model} com rate limit. Alternando para {new_model}")
        
        return True
    
    def reset_to_primary(self) -> None:
        """Reseta para o modelo primÃ¡rio (usar apÃ³s perÃ­odo de cooldown)."""
        if self.current_index > 0:
            old_model = self.current_model_id
            self.current_index = 0
            logger.info(f"ðŸ”„ Resetando para modelo primÃ¡rio: {old_model} -> {self.current_model_id}")
    
    def should_try_primary(self) -> bool:
        """
        Verifica se deve tentar voltar ao modelo primÃ¡rio.
        Retorna True se passou tempo suficiente desde o Ãºltimo fallback.
        """
        # Se jÃ¡ estÃ¡ no primÃ¡rio, nÃ£o precisa
        if self.current_index == 0:
            return False
        
        # Cooldown de 5 minutos antes de tentar primÃ¡rio novamente
        cooldown_seconds = 300
        elapsed = time.time() - self.last_switch_time
        
        if elapsed > cooldown_seconds:
            logger.info(f"â° Cooldown de {cooldown_seconds}s passou. Tentando modelo primÃ¡rio...")
            return True
        
        return False
    
    def record_error(self, model_id: str) -> None:
        """Registra erro para um modelo especÃ­fico."""
        if model_id in self.error_counts:
            self.error_counts[model_id] += 1
            logger.debug(f"ðŸ“Š Erros em {model_id}: {self.error_counts[model_id]}")


# ============================================================================
# FUNÃ‡Ã•ES DE CONVENIÃŠNCIA
# ============================================================================

# InstÃ¢ncia global do gerenciador
_fallback_manager: Optional[GeminiFallbackManager] = None


def get_fallback_manager() -> GeminiFallbackManager:
    """Retorna a instÃ¢ncia singleton do gerenciador de fallback."""
    global _fallback_manager
    if _fallback_manager is None:
        _fallback_manager = GeminiFallbackManager()
    return _fallback_manager


def get_model_with_fallback(temperature: float = 0.3) -> Gemini:
    """
    Retorna modelo Gemini atual da chain de fallback.
    
    Esta funÃ§Ã£o Ã© o ponto de entrada principal para obter um modelo.
    O modelo retornado depende do estado atual da chain de fallback.
    
    Args:
        temperature: Temperatura do modelo (padrÃ£o: 0.3)
        
    Returns:
        Gemini: InstÃ¢ncia do modelo atual
    """
    manager = get_fallback_manager()
    
    # Tentar voltar ao primÃ¡rio apÃ³s cooldown
    if manager.should_try_primary():
        manager.reset_to_primary()
    
    return manager.get_model(temperature)


def is_rate_limit_error(exception: Exception) -> bool:
    """
    Verifica se uma exceÃ§Ã£o Ã© um erro de rate limit (429).
    
    Args:
        exception: ExceÃ§Ã£o a ser verificada
        
    Returns:
        bool: True se Ã© erro 429
    """
    error_msg = str(exception).lower()
    
    # Checar por indicadores de rate limit
    rate_limit_indicators = [
        "429",
        "rate limit",
        "rate_limit",
        "quota exceeded",
        "resource has been exhausted",
        "too many requests",
        "resourceexhausted",
    ]
    
    return any(indicator in error_msg for indicator in rate_limit_indicators)


def run_with_fallback(
    func: Callable,
    *args,
    max_retries: int = MAX_RETRIES_PER_MODEL,
    **kwargs
) -> Any:
    """
    Executa uma funÃ§Ã£o com retry automÃ¡tico e fallback de modelo em caso de 429.
    
    Esta funÃ§Ã£o:
    1. Tenta executar a funÃ§Ã£o passada
    2. Em caso de erro 429, faz retry com backoff exponencial
    3. Se esgotar retries, alterna para prÃ³ximo modelo na chain
    4. Repete atÃ© sucesso ou esgotar todos os modelos
    
    Args:
        func: FunÃ§Ã£o a ser executada (ex: agent.run)
        *args: Argumentos posicionais para a funÃ§Ã£o
        max_retries: MÃ¡ximo de retries por modelo antes de fazer fallback
        **kwargs: Argumentos nomeados para a funÃ§Ã£o
        
    Returns:
        Resultado da funÃ§Ã£o executada
        
    Raises:
        Exception: Re-levanta a Ãºltima exceÃ§Ã£o se todos os modelos falharem
    """
    manager = get_fallback_manager()
    last_exception = None
    
    # Tentar voltar ao primÃ¡rio se cooldown passou
    if manager.should_try_primary():
        manager.reset_to_primary()
    
    # Loop atravÃ©s dos modelos na chain
    while True:
        current_model = manager.current_model_id
        
        # Retry loop para o modelo atual
        for retry in range(max_retries):
            try:
                result = func(*args, **kwargs)
                
                # Sucesso! Resetar contador de erros do modelo
                manager.error_counts[current_model] = 0
                return result
                
            except Exception as e:
                last_exception = e
                
                if is_rate_limit_error(e):
                    manager.record_error(current_model)
                    
                    if retry < max_retries - 1:
                        # Backoff exponencial antes de retry
                        backoff = min(
                            INITIAL_BACKOFF_SECONDS * (BACKOFF_MULTIPLIER ** retry),
                            MAX_BACKOFF_SECONDS
                        )
                        logger.warning(
                            f"â³ Rate limit em {current_model}. "
                            f"Retry {retry + 1}/{max_retries} em {backoff}s..."
                        )
                        time.sleep(backoff)
                    else:
                        # Esgotar retries para este modelo, tentar prÃ³ximo
                        logger.warning(
                            f"âŒ Esgotaram {max_retries} retries em {current_model}. "
                            f"Tentando fallback..."
                        )
                else:
                    # Erro nÃ£o relacionado a rate limit, re-levantar imediatamente
                    logger.error(f"âŒ Erro nÃ£o-related a rate limit: {e}")
                    raise
        
        # Tentar prÃ³ximo modelo na chain
        if not manager.switch_to_next_model():
            # NÃ£o hÃ¡ mais modelos, re-levantar Ãºltima exceÃ§Ã£o
            logger.error("ðŸ’€ Todos os modelos na chain de fallback falharam!")
            raise last_exception


# ============================================================================
# DECORATOR PARA FUNÃ‡Ã•ES COM FALLBACK AUTOMÃTICO
# ============================================================================

def with_model_fallback(max_retries: int = MAX_RETRIES_PER_MODEL):
    """
    Decorator que adiciona retry com fallback automÃ¡tico a uma funÃ§Ã£o.
    
    Uso:
        @with_model_fallback(max_retries=3)
        def minha_funcao_com_llm(prompt):
            agent = Agent(model=get_model_with_fallback())
            return agent.run(prompt)
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            return run_with_fallback(func, *args, max_retries=max_retries, **kwargs)
        return wrapper
    return decorator


# ============================================================================
# TESTES
# ============================================================================

if __name__ == "__main__":
    print("ðŸ§ª Testando GeminiFallbackManager...")
    
    manager = get_fallback_manager()
    
    print(f"ðŸ“‹ Modelo atual: {manager.current_model_id}")
    print(f"ðŸ“‹ Chain completa: {manager.model_chain}")
    
    # Simular fallback
    print("\nðŸ”„ Simulando fallback...")
    manager.switch_to_next_model()
    print(f"ðŸ“‹ Novo modelo: {manager.current_model_id}")
    
    manager.switch_to_next_model()
    print(f"ðŸ“‹ Novo modelo: {manager.current_model_id}")
    
    # Reset
    print("\nðŸ”„ Resetando para primÃ¡rio...")
    manager.reset_to_primary()
    print(f"ðŸ“‹ Modelo apÃ³s reset: {manager.current_model_id}")
    
    print("\nâœ… Testes concluÃ­dos!")
